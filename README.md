# Bankruptcy Prediction â€“ Lab 5

## ğŸ“Œ Overview
This project implements a **Bankruptcy Prediction System** using three machine learning models:
- Logistic Regression
- Random Forest
- XGBoost

The workflow follows **16 clearly defined steps**, from data preprocessing to explainability.  
The goal is to predict whether a company will go bankrupt based on financial ratios.

---

## ğŸ“‚ Project Structure
```bash
â”‚â”€â”€ data/
â”‚ â”œâ”€â”€ data.csv
â”‚
â”‚â”€â”€ lab5_analysis.ipynb
â”‚
â”‚â”€â”€ test.py
â”‚
â”‚â”€â”€ README.md
â”‚â”€â”€ requirements.txt

```

---

## ğŸ›  16-Part Approach Summary

1. **Model Selection** â€“ Logistic Regression, Random Forest, XGBoost  
2. **Data Preprocessing** â€“ Cleaning, removing duplicates, irrelevant features  
3. **Class Imbalance Handling** â€“ Class weights, stratified splits  
4. **Outlier Handling** â€“ Kept extreme values for interpretability, scaled for LR  
5. **Sampling Bias Check** â€“ Population Stability Index (PSI)  
6. **Normalization** â€“ StandardScaler for LR only  
7. **Normality Testing** â€“ Addressed highly skewed features if needed  
8. **PCA** â€“ Skipped to preserve interpretability  
9. **Feature Engineering** â€“ Minimal, avoided overfitting  
10. **Multicollinearity** â€“ Removed features with correlation > 0.9  
11. **Feature Selection** â€“ Used XGBoost importance + correlation checks  
12. **Hyperparameter Tuning** â€“ Random Search + Grid Search  
13. **Cross-Validation** â€“ Stratified K-Fold  
14. **Evaluation Metrics** â€“ F1, ROC-AUC, PR-AUC  
15. **Model Drift Monitoring** â€“ PSI for post-deployment checks  
16. **Explainability** â€“ SHAP values for model interpretation  

---

## ğŸ“Š Visualizations
The following plots are generated:
- Correlation heatmap
- ROC curves for all models
- Precision-Recall curves
- Feature importance plots
- SHAP summary plot

---

## â–¶ How to Run

### 1ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt
```
2ï¸âƒ£ Run Analysis
```bash
python src/modeling.py
Or open the Jupyter Notebook:
```
```bash
jupyter notebook notebooks/lab5_analysis.ipynb
```
3ï¸âƒ£ View Results
Evaluation metrics will be printed in the console.

Plots will be saved in outputs/.

SHAP explanations will be in outputs/shap_plots/.

ğŸ“¦ Requirements
```bash
- pandas
- numpy
- scikit-learn
- xgboost
- matplotlib
- seaborn
- shap
```
ğŸ“ˆ Results Summary
- Best Model: XGBoost (highest ROC-AUC and F1 score)

- Logistic Regression offered better interpretability

- Random Forest performed close to XGBoost but with slightly lower precision

ğŸ“œ License
This is an academic project for Lab 5.
Feel free to adapt for learning purposes.

